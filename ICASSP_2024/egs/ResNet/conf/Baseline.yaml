# train configuration

exp_dir: 'exp'

# Data Loader
batch_size: 256
num_workers: 8
min_frames: 200
max_frames: 201
eval_frames: 0
max_seg_per_spk: 500 # Maximum number of utterances per speaker per epoch
nPerSpeaker: 1 # Number of utterances per speaker per batch, only for metric learning based losses
sample_rate: 16000
aug_prob: 0.6
speed_perturb: False

# Training details
max_epochs: 100
loss_type: 'aamsoftmax' # softmax, amsoftmax, aamsoftmax
nnet_type: 'ResNet34' # TDNN, ECAPA_TDNN, ResNet34, ResNet34L
pooling_type: 'ASP'
eval_interval: 10
keep_loss_weight: False

# Optimizer
learning_rate: 0.01
lr_step_size: 5
lr_gamma: 0.9
auto_lr: False
warm_up_epoch: 5

# Loss functions
margin: 0.2
scale: 32
margin_scheduler:
  update_margin: True
  initial_margin: 0.0
  final_margin: 0.2
  increase_start_epoch: 20
  fix_start_epoch: 40
  increase_type: 'exp'

# Training and test data
apply_metric: True
data_key_level: 2 # CN-Celeb: 2, VoxCeleb: 3

# Load and save
save_interval: 1
last_n: 10 # Change the `last_n` parameter in stage5 of run.sh correspondingly

# Model definition
n_mels: 80
embedding_dim: 256


consistency_loss:
  add_loss: False
  loss_a_type: 'Baseline'