# train configuration

exp_dir: 'exp'

# Data Loader
batch_size: 128  # batch_size :Number of people sampled per minibatch
num_workers: 8
min_frames: 200
max_frames: 201
eval_frames: 0
max_seg_per_spk: 500 # Maximum number of utterances per speaker per epoch
nPerSpeaker: 1 # Number of utterances per speaker per batch, only for metric learning based losses
sample_rate: 16000
aug_prob: 0.6
speed_perturb: False

# Training details
max_epochs: 10
loss_type: 'aamsoftmax' # softmax, amsoftmax, aamsoftmax
nnet_type: 'ResNet34' # TDNN, ECAPA_TDNN, ResNet34, ResNet34L
pooling_type: 'ASP'
eval_interval: 1
keep_loss_weight: False

# Optimizer
learning_rate: 0.00008
lr_step_size: 1
lr_gamma: 0.9
auto_lr: False

# Loss functions
margin: 0.2
scale: 32

margin_scheduler:
  update_margin: False
  initial_margin: 0.0
  final_margin: 0.2
  increase_start_epoch: 20
  fix_start_epoch: 40
  increase_type: 'exp'

# Training and test data
apply_metric: True
data_key_level: 2 # CN-Celeb: 2, VoxCeleb: 3

# Load and save
save_interval: 1
last_n: 10 # Change the `last_n` parameter in stage5 of run.sh correspondingly

# Model definition
n_mels: 80
embedding_dim: 256

# Domain alignment loss
consistency_loss:
  add_loss: True
  loss_a_type: "coral"
  weight: 0.1