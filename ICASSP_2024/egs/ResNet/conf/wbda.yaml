# train configuration

exp_dir: 'exp'

# Data Loader
batch_size: 32 # batch_size :Number of people sampled per minibatch
num_workers: 8
min_frames: 200
max_frames: 201
eval_frames: 0
max_seg_per_spk: 500 # Maximum number of utterances per speaker per epoch
nPerSpeaker: 16 # Number of utterances per speaker per batch, only for metric learning based losses
sample_rate: 16000
aug_prob: 0.6
speed_perturb: False

# Training details
max_epochs: 8
loss_type: 'aamsoftmax' # softmax, amsoftmax, aamsoftmax
nnet_type: 'ResNet34' # TDNN, ECAPA_TDNN, ResNet34, ResNet34L
pooling_type: 'ASP'
eval_interval: 1
keep_loss_weight: False


# Optimizer
learning_rate: 0.00008
lr_step_size: 1
lr_gamma: 0.9
auto_lr: False

# Loss functions
margin: 0.2
scale: 32

margin_scheduler:
  update_margin: False
  initial_margin: 0.5
  final_margin: 0.5
  increase_start_epoch: 1
  fix_start_epoch: 1
  increase_type: 'exp'


# Training and test data
apply_metric: True
data_key_level: 2 # CN-Celeb: 2, VoxCeleb: 3

# Load and save
save_interval: 1
last_n: 7 # Change the `last_n` parameter in stage5 of run.sh correspondingly

# Model definition
n_mels: 80
embedding_dim: 256

# Domain alignment loss
consistency_loss:
  add_loss: True
  loss_a_type: "wbda"
  weight: 0.9
  weight_in: 0.9
  weight_bet: 0.02
  matric_type: 0

